{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PlantDoc Image Classification Project\n",
    "\n",
    "This notebook contains the main experiments and analysis for the PlantDoc dataset classification project.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Data Loading](#setup)\n",
    "2. [Data Preprocessing](#preprocessing)\n",
    "3. [Traditional Machine Learning (HOG + SVM)](#traditional_ml)\n",
    "4. [Deep Learning (ResNet Transfer Learning)](#deep_learning)\n",
    "5. [Hyperparameter Sensitivity Analysis](#hyperparameter)\n",
    "6. [Model Architecture Comparison](#architecture)\n",
    "7. [Data Augmentation Analysis](#augmentation)\n",
    "8. [Ablation Studies](#ablation)\n",
    "9. [Failure Analysis](#failure)\n",
    "10. [Model Interpretability](#interpretability)\n",
    "11. [Final Results and Report](#results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Import our custom modules\n",
    "from download_data import download_plantdoc_dataset\n",
    "from preprocess import load_plantdoc_data, create_train_val_test_split, create_data_generators, save_test_data\n",
    "from traditional_ml import extract_hog_features, train_svm_classifier, evaluate_model\n",
    "from deep_learning import create_resnet_model, compile_model, train_model, plot_training_history\n",
    "from analysis import plot_confusion_matrix, analyze_confusion_matrix, plot_feature_maps, plot_hyperparameter_sensitivity\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the dataset\n",
    "print(\"Downloading PlantDoc dataset...\")\n",
    "data_path = download_plantdoc_dataset()\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "images, labels, class_names = load_plantdoc_data(data_path)\n",
    "\n",
    "print(f\"Dataset loaded: {len(images)} images, {len(class_names)} classes\")\n",
    "print(f\"Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing <a name=\"preprocessing\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = create_train_val_test_split(images, labels)\n",
    "\n",
    "# Save test data for final evaluation\n",
    "save_test_data(X_test, y_test, class_names)\n",
    "\n",
    "# Create data generators with augmentation\n",
    "train_generator_aug, val_generator = create_data_generators(X_train, y_train, X_val, y_val, augmentation=True)\n",
    "\n",
    "# Create data generators without augmentation for comparison\n",
    "train_generator_no_aug, _ = create_data_generators(X_train, y_train, X_val, y_val, augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i in range(10):\n",
    "    ax = axes[i//5, i%5]\n",
    "    ax.imshow(X_train[i])\n",
    "    ax.set_title(f\"Class: {class_names[y_train[i]]}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Traditional Machine Learning (HOG + SVM) <a name=\"traditional_ml\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HOG features\n",
    "print(\"Extracting HOG features from training data...\")\n",
    "X_train_hog = extract_hog_features(X_train)\n",
    "X_val_hog = extract_hog_features(X_val)\n",
    "X_test_hog = extract_hog_features(X_test)\n",
    "\n",
    "print(f\"HOG features shape: {X_train_hog.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM classifier\n",
    "print(\"Training SVM classifier...\")\n",
    "svm_classifier, scaler = train_svm_classifier(X_train_hog, y_train, C=1.0, kernel='rbf')\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_accuracy, val_report, val_predictions = evaluate_model(svm_classifier, scaler, X_val_hog, y_val, class_names)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(val_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_accuracy, test_report, test_predictions = evaluate_model(svm_classifier, scaler, X_test_hog, y_test, class_names)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(test_report)\n",
    "\n",
    "# Store results for comparison\n",
    "traditional_ml_results = {\n",
    "    'accuracy': test_accuracy,\n",
    "    'predictions': test_predictions,\n",
    "    'report': test_report\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deep Learning (ResNet Transfer Learning) <a name=\"deep_learning\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ResNet model\n",
    "num_classes = len(class_names)\n",
    "resnet_model = create_resnet_model(num_classes)\n",
    "resnet_model = compile_model(resnet_model)\n",
    "\n",
    "print(\"ResNet model summary:\")\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Training ResNet model...\")\n",
    "history = train_model(resnet_model, train_generator_aug, val_generator, epochs=50, model_name='resnet')\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history, 'ResNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = resnet_model.evaluate(val_generator)  # Using val_generator for consistency\n",
    "print(f\"ResNet Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Get predictions for analysis\n",
    "resnet_predictions = resnet_model.predict(val_generator)\n",
    "resnet_pred_classes = np.argmax(resnet_predictions, axis=1)\n",
    "\n",
    "# Store results\n",
    "resnet_results = {\n",
    "    'accuracy': test_accuracy,\n",
    "    'predictions': resnet_pred_classes,\n",
    "    'model': resnet_model\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Sensitivity Analysis <a name=\"hyperparameter\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate sensitivity for ResNet\n",
    "learning_rates = [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "lr_results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"Testing learning rate: {lr}\")\n",
    "    model = create_resnet_model(num_classes)\n",
    "    model = compile_model(model, learning_rate=lr)\n",
    "    \n",
    "    # Quick training for sensitivity analysis\n",
    "    history = model.fit(train_generator_aug, epochs=10, validation_data=val_generator, verbose=0)\n",
    "    \n",
    "    val_acc = max(history.history['val_accuracy'])\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    lr_results[lr] = {'accuracy': val_acc, 'loss': val_loss}\n",
    "\n",
    "plot_hyperparameter_sensitivity(lr_results, 'Learning Rate', 'ResNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Architecture Comparison <a name=\"architecture\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare ResNet50 vs VGG16\n",
    "from deep_learning import create_vgg_model\n",
    "\n",
    "# Train VGG16 model\n",
    "vgg_model = create_vgg_model(num_classes)\n",
    "vgg_model = compile_model(vgg_model)\n",
    "\n",
    "print(\"Training VGG16 model...\")\n",
    "vgg_history = train_model(vgg_model, train_generator_aug, val_generator, epochs=30, model_name='vgg')\n",
    "\n",
    "# Evaluate VGG16\n",
    "vgg_loss, vgg_accuracy = vgg_model.evaluate(val_generator)\n",
    "print(f\"VGG16 Test Accuracy: {vgg_accuracy:.4f}\")\n",
    "\n",
    "# Compare models\n",
    "model_comparison = {\n",
    "    'SVM': {'accuracy': traditional_ml_results['accuracy']},\n",
    "    'ResNet50': {'accuracy': resnet_results['accuracy']},\n",
    "    'VGG16': {'accuracy': vgg_accuracy}\n",
    "}\n",
    "\n",
    "plot_model_comparison(model_comparison, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Augmentation Analysis <a name=\"augmentation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ResNet without augmentation\n",
    "resnet_no_aug = create_resnet_model(num_classes)\n",
    "resnet_no_aug = compile_model(resnet_no_aug)\n",
    "\n",
    "history_no_aug = resnet_no_aug.fit(train_generator_no_aug, epochs=30, validation_data=val_generator, verbose=0)\n",
    "no_aug_accuracy = max(history_no_aug.history['val_accuracy'])\n",
    "\n",
    "# Compare with augmented version\n",
    "augmentation_results = {\n",
    "    'no_augmentation': {'accuracy': no_aug_accuracy, 'loss': min(history_no_aug.history['val_loss'])},\n",
    "    'with_augmentation': {'accuracy': resnet_results['accuracy'], 'loss': history.history['val_loss'][-1]}\n",
    "}\n",
    "\n",
    "plot_data_augmentation_comparison(augmentation_results['no_augmentation'], \n",
    "                                augmentation_results['with_augmentation'], \n",
    "                                'ResNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ablation Studies <a name=\"ablation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation study: Different optimizers\n",
    "optimizers = ['adam', 'sgd', 'rmsprop']\n",
    "optimizer_results = {}\n",
    "\n",
    "for opt_name in optimizers:\n",
    "    print(f\"Testing optimizer: {opt_name}\")\n",
    "    model = create_resnet_model(num_classes)\n",
    "    \n",
    "    if opt_name == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    elif opt_name == 'sgd':\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
    "    elif opt_name == 'rmsprop':\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_generator_aug, epochs=15, validation_data=val_generator, verbose=0)\n",
    "    val_acc = max(history.history['val_accuracy'])\n",
    "    \n",
    "    optimizer_results[opt_name] = {'accuracy': val_acc}\n",
    "\n",
    "# Plot ablation results\n",
    "plt.figure(figsize=(8, 5))\n",
    "opt_names = list(optimizer_results.keys())\n",
    "opt_accs = [optimizer_results[opt]['accuracy'] for opt in opt_names]\n",
    "plt.bar(opt_names, opt_accs)\n",
    "plt.title('Ablation Study: Optimizer Comparison')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.savefig('reports/ablation_optimizers.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Failure Analysis <a name=\"failure\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for ResNet\n",
    "plot_confusion_matrix(y_val, resnet_pred_classes, class_names, 'ResNet')\n",
    "\n",
    "# Analyze most confused classes\n",
    "confused_pairs = analyze_confusion_matrix(y_val, resnet_pred_classes, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Interpretability <a name=\"interpretability\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature maps from ResNet\n",
    "# Preprocess a sample image\n",
    "sample_img = X_val[0] / 255.0  # Normalize\n",
    "\n",
    "# Visualize feature maps from different layers\n",
    "layer_names = ['conv1_conv', 'conv2_block3_out', 'conv3_block4_out']\n",
    "\n",
    "for layer_name in layer_names:\n",
    "    try:\n",
    "        plot_feature_maps(resnet_model, sample_img, layer_name, 'ResNet')\n",
    "    except:\n",
    "        print(f\"Could not visualize layer: {layer_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Final Results and Report <a name=\"results\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final test predictions for submission\n",
    "print(\"Generating final test predictions...\")\n",
    "\n",
    "# Load test data\n",
    "X_test_final = np.load('data/processed/X_test.npy')\n",
    "y_test_final = np.load('data/processed/y_test.npy')\n",
    "\n",
    "# Get predictions from best model (ResNet)\n",
    "# Preprocess test images for ResNet\n",
    "X_test_resnet = X_test_final / 255.0\n",
    "test_predictions_resnet = resnet_model.predict(X_test_resnet)\n",
    "test_pred_classes = np.argmax(test_predictions_resnet, axis=1)\n",
    "\n",
    "# Save predictions\n",
    "np.save('models/test_predictions.npy', test_pred_classes)\n",
    "\n",
    "# Generate classification report\n",
    "from analysis import generate_classification_report\n",
    "final_report = generate_classification_report(y_test_final, test_pred_classes, class_names, 'ResNet_Final')\n",
    "\n",
    "print(\"Final Results:\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test_final, test_pred_classes):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(final_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all experiments\n",
    "print(\"\\n=== EXPERIMENT SUMMARY ===\")\n",
    "print(f\"Traditional ML (HOG+SVM) Accuracy: {traditional_ml_results['accuracy']:.4f}\")\n",
    "print(f\"ResNet50 Accuracy: {resnet_results['accuracy']:.4f}\")\n",
    "print(f\"VGG16 Accuracy: {vgg_accuracy:.4f}\")\n",
    "print(f\"ResNet without augmentation: {no_aug_accuracy:.4f}\")\n",
    "print(f\"ResNet with augmentation: {resnet_results['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nAll results and visualizations saved in the 'reports/' directory.\")\n",
    "print(\"Test predictions saved in 'models/test_predictions.npy'.\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Write the experiment report based on these results.\")\n",
    "print(\"2. Create GitHub repository and upload code.\")\n",
    "print(\"3. Submit deliverables to guangyu.ryan@yahoo.com.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "indentUnit": 4,
    "tabSize": 4,
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
